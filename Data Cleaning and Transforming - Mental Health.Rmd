---
title: "Data Cleaning and Transforming - Mental Health"
author: "Hasham Zahid"
date: "2024-01-09"
output:
  pdf_document: default
  html_document: default
---

**The Data, Attribute Information and Cleaning Process** 

Data Source [https://www.kaggle.com/datasets/thedevastator/uncover-global-trends-in-mental-health-disorder]

The dataset is messy because it is 4 different tables in 1 excel file without any separation. For example, after approximately row 6400, the new table starts but it is in the same column as the the table before. That means columns 4 or 5 are completely different attributes depending on which row you are in. An outline of the tables and attributes is further provided. This notebook will clean up the entire CSV file and split into the 4 tables respectively, which will then be used for analysis. The data will only focus on yearly values from 1990 to 2017. In summary, the purpose of this notebook is to extract each individual table into its own entity so that it may be cleaned and transformed, and data analysis may be performed.

**Note** All tables share the first few columns with each other. The attributes shared are:

Entity: Unique identifier for each country or region included in the data set.
Code: Unique code associated with an Entity/Country or region included in the data set.
Year: Year that the data about that particular Entity/Country was collected.

After this, the tables have different features.

**Table 1: Mental Health Disorders in %**

Schizophrenia (%): Percentage of people with schizophrenia in that country/region during that year.
Bipolar disorder (%): Percentage of people with Bipolar Disorders in that country/region during that year.
Eating disorders (%): Percentage of people with Eating Disorders in that country/region during that year.
Anxiety disorders (%): Percentage of people with Anxiety disorders in that country/region during that year.
Drug use disorders (%): Percentage of people with Drug use disorders in that country/region during that year.
Depression (%): Percentage of people with Depression in that country/region during that year.
Alcohol use disorders (%): Percentage of people with alcohol use disorders in that country/region during that year.

**Table 2: Mental Health Disorder Per Sex in %**

Prevalence in males (%): Percentage of mental health disorders in males in that country during that year.
Prevalence in females (%):  Percentage of mental health disorders in females in that country during that year.

**Table 3: Table 3: Suicide and Depression per 100k inhabitants**

Suicide rate (deaths per 100,000 individuals): Suicide deaths/100,000 in that country in that year.
Depressive disorder rates (number suffering per 100,000): Number of individuals suffering from depression per 100,000 in that country in that year.
Population: The total population.

**Table 4: Total Prevalence - Depressive Disorders**
Prevalence - Depressive Disorders: The total number of people suffering from depression in that country during that year. This is for both sexes and all ages combined. In other words, the total number of people suffering from depressive disorders. This is not a percentage or a rate. 


**Loading the Dataset**

```{r}
library(dplyr)
library(tidyr)
library(tidyverse)
```


```{r}
#Loading in the Dataset
mental_health <- read.csv("Mental health Depression disorder Data.csv",
                          header = TRUE,
                          stringsAsFactors = FALSE,
                          na.strings = c("", "?", "null"))
```


```{r}
head(mental_health)
```
```{r}
dim(mental_health)
```

```{r}
#Dropping the index column as it is not required for analysis
mental_health <- mental_health[,-1]
```


```{r}
head(mental_health)
```

**Table 1: Cleaning:**

We will remove any missing values, if they do make sense, as well as clean up any spelling errors or other mistakes. The headers of the dataset will also be made consistent and more neat. 

The row positions were determined by clicking on the dataset in R and sorting by descending order to see which rows had alphabets instead of numbers. Row 6468 is where table 2 begins.

```{r}
#Isolating the first table
#All columns will be kept as there are the most amount of columns in the first table
table_1 <- mental_health[1:6468, ]
```

```{r}
#table 1 consists of 6468 rows and 10 observations 
tail(table_1)
```
```{r}
#Renaming the columns so they are more consistent and easier to understand.
colnames(table_1) <- c("Country", "Code", "Year", "Schizophrenia","Bipolar Disorder", "Eating Disorders", "Anxiety Disorders", "Drug Use Disorders", "Depression", "Alcohol Use Disorders")
```

```{r}
#checking column types
sapply(table_1, class)
```
```{r}
#changing column types to be more consistent
#Keeping entity and code as character, changing the rest to numeric 
columns <- c("Year", "Schizophrenia", "Bipolar Disorder", "Eating Disorders")

table_1[columns] <- lapply(table_1[columns], as.numeric)

```

```{r}
sapply(table_1, class)
```

```{r}
#Finding the percentage of missing values in each column of table 1
colMeans(is.na(table_1)) * 100
```
It seems there are no missing values in any of the columns except the 'Code' column. This column refers to the three letter unique code assigned for each country. Lets find out which countries are missing the code and assign them the proper codes.

```{r}
#Finding out which countries are missing the code
#We do this by retrieving missing values for the 'Code' column, then isolating the missing values by country and retrieving only the unique country name.
unique(subset(table_1, is.na(Code))$Country)
```

It seems that most of these values are not for COUNTRIES but rather for REGIONS instead, such as Africa and North America. There are some other values in there for countries however, such as England and Scotland (however, these values are already included in the 'United Kingdom' rows, as these countries are part of that region). The easiest way to fix this would be to just remove the values from the dataset, as for analysis the regions are not as important as the countries themselves.

```{r}
#Dropping all missing values from the Code column
#we are using complete.cases beecause we do not want a subset using na.omit, but actually remove the rows from our dataset
table_1 <- table_1[complete.cases(table_1$Code), ]
```


```{r}
#Checking to see percentage of missing rows again 
colMeans(is.na(table_1)) * 100
```
Along with this, we will also be dropping the aggregated data for the World as well. The dataset will only contain country information, not regional or overall global data. 

```{r}
#Dropping "world" data from the table
#this will filter the column and only keep the data where the country does not equal world 
table_1 <- table_1 %>% filter(table_1$Country != 'World')
```


```{r}
dim(table_1)
```


**Table 2: Cleaning**

```{r}
#This will give us the second table, as well as the 6 features of that table
table_2 <- mental_health[6470:54276 , 1:6]
```

```{r}
head(table_2)
```
First thing we have to do rename the columns to the write variables, which were listed above. 

```{r}
#Renaming columns 
colnames(table_2) <- c("Country", "Code", "Year", "Prevalence in Males", "Prevalence in Females", "Population")
```

```{r}
head(table_2)
```
Next lets fix the column classes, like we did with the first table.

```{r}
##checking column types
sapply(table_2, class)
```
As expected, they are all characters. We need to make the latter 4 numeric variables.

```{r}
#Changing column types for table 2 
columns2 <- c("Year", "Prevalence in Males", "Prevalence in Females", "Population")

table_2[columns2] <- lapply(table_2[columns2], as.numeric)
```

```{r}
sapply(table_2, class)
```


Lets check the percentage of missing values per column.

```{r}
#Missing values percentage by column
colMeans(is.na(table_2) * 100)
```
There seems to be a large number of missing values in the male and female columns. Just looking at the data quickly, this is most likely because there is no data from before 1990 and after 2017 for these columns, but the years are still added the data file. An easy fix would be to remove all rows from before the year 1990 and after the year 2017. The Cove variable also seems to have missing values, this is most likely the same reason as before. Lets start with the code variable. 

```{r}
#Code variable missing values 
unique(subset(table_2, is.na(Code))$Country)
```

As expected its the same reason as before. We will deal with this by just removing the rows entirely.

```{r}
#removing missing code values 
table_2 <- table_2[complete.cases(table_2$Code), ]
```

```{r}
#Also removing the world code from the dataset
table_2 <- table_2 %>% filter(table_2$Country != 'World')
```

Lets move on to dealing with the yearly values and removing them. 

```{r}
#Removing all rows before the year 1990 and after the year 2017.
table_2 <- table_2[table_2$Year >= 1990 & table_2$Year <= 2017, , drop = FALSE]
```


```{r}
#Checking missing values percentages
colMeans(is.na(table_2) * 100)
```
It seems there are still some missing values in the two columns, so we should see which country these are for.

```{r}
#distinct values for countries that have missing data for prevalence rates.
unique(subset(table_2, is.na(`Prevalence in Males`))$Country)
```
There are countries in this table that weren't included in the first one. We will remove those countries from the data set to keep everything consistent.

```{r}
#Removing all rows for countries which have missing values in males and females columns
males <- unique(subset(table_2, is.na(`Prevalence in Males`))$Country)
females <- unique(subset(table_2, is.na(`Prevalence in Females`))$Country)

table_2 <- table_2[!(table_2$Country %in% males), , drop = FALSE]
table_2 <- table_2[!(table_2$Country %in% females), , drop = FALSE]

```

```{r}
colMeans(is.na(table_2) * 100)
```
```{r}
dim(table_2)
```

**Table 3: Cleaning**


```{r}
#The third table is about suicide rates per 100,000. This will give us the data on it and its 5 variables.
#NOTE: The third table techincally has '6' variables, however, the last variable is 'Population'. This is already included in our second table and thus it isn't needed in this one. 
table_3 <- mental_health[54278:102084 , 1:5]
```

```{r}
head(table_3)
```
This table seems very similar to table 2, so we will most likely deal with it in the same manner. First by removing the missing codes, than the missing years, then whatever else is left over. 

First lets rename the variables and change column types to numeric if needed.


```{r}
#Renaming variables and changing class type
colnames(table_3) <- c("Country", "Code", "Year", 'Suicide Rates Per 100,000', 'Depressive Disorders Per 100,000')
```


```{r}
#Class type table 3
sapply(table_3, class)
```
```{r}
#Changing class types from character to numeric for numeric variables
columns3 <- c("Year", 'Suicide Rates Per 100,000', 'Depressive Disorders Per 100,000')

table_3[columns3] <- lapply(table_3[columns3], as.numeric)
```

```{r}
sapply(table_3, class)
```

Time to handle missing values, lets checking missing percentages.

```{r}
#missing percentages for table_3
colMeans(is.na(table_3) * 100)
```

As expected, its very similar to the previous table. Lets deal with the code first, then the years. We will just repeat what we did with the second table, however, we'll still make sure that what we're doing makes sense.

```{r}
unique(subset(table_3, is.na(Code))$Country)
```
```{r}
#removing missing code values 
table_3 <- table_3[complete.cases(table_3$Code), ]
```

```{r}
#Also removing the world code from the dataset
table_3 <- table_3 %>% filter(table_3$Country != 'World')
```


Time to deal with the years before 1990 and after 2017. Remember, this dataset for this analysis will only go from 1990 to 2017. Additionally, it will focus only on country data, so no regions or aggregated world data. This is the reason we remove the regions from the dataset, as well as the world variable.  

```{r}
#Removing all rows from before 1990 and after 2017.
table_3 <- table_3[table_3$Year >= 1990 & table_3$Year <= 2017, , drop = FALSE]
```

```{r}
colMeans(is.na(table_3)) *100
```
It seems there are still some missing values here, so let's check for which country.

```{r}
#missing rows for suicide and depressive for unique countries.
unique(subset(table_3, is.na(`Suicide Rates Per 100,000`))$Country)
```

Just like table 2, it seems this is missing data for small soverign states. We will remove this data from the table to keep the dataset consistent. 

```{r}
#Removing all missing rows from the suicides and depression variables.
suicide <- unique(subset(table_3, is.na(`Suicide Rates Per 100,000`))$Country)
depression <- unique(subset(table_3, is.na(`Depressive Disorders Per 100,000`))$Country)

table_3 <- table_3[!(table_3$Country %in% suicide), , drop = FALSE]
table_3 <- table_3[!(table_3$Country %in% depression), , drop = FALSE]
```


```{r}
colMeans(is.na(table_3) * 100)

dim(table_3)
```


**Table 4: Cleaning**

This table only has one variable. Total Prevalence of Depressive disorders for that given country in that given year. It is not a rate, or a percentage. This is for both sexes and all ages combined.


```{r}
#Isolating the final tables data. 
table_4 <- mental_health[102086:108553, 1:4]
```

```{r}
#Checking the column names for table 4
head(table_4)
```

```{r}
#checking class types
sapply(table_4, class)
```


```{r}
#table dimensions 
dim(table_4)
```
It seems this table does not have as many missing variables, most likely only the missing country codes to deal with, similar to the first table.

```{r}
#Renaming columns for table 4
colnames(table_4) <- c("Country", "Code", "Year", 'Total Prevalence of Depressive Disorders')
```


```{r}
#changing class types
columns4 <- c("Year", 'Total Prevalence of Depressive Disorders')

table_4[columns4] <- lapply(table_4[columns4], as.numeric)
```


```{r}
#missing percentages for each variable
colMeans(is.na(table_4)*100)
```
As expected, the code variable is the one missing the values. Lets check to see if its still the region data or if there are any actual countries with missing codes.

```{r}
#missing codes for countries 
unique(subset(table_4, is.na(Code))$Country)
```
```{r}
#removing missing codes from the table
table_4 <- table_4[complete.cases(table_4$Code), ]
#Also removing the world code from the dataset
table_4 <- table_4 %>% filter(table_4$Country != 'World')
```

```{r}
#rechecking missing percentages
colMeans(is.na(table_4)*100)
```


**Exporting the tables to CSV files**

Time to export our table dataframes to a CSV. I will do this here, and then merge all the tables together at the very end using Excel, since the country, code and year are shared between the tables. This will give me a final table with 5460 obs and 16 variables. 

We have cleaned our dataset from 4 tables, 108553 obs and 10 variables to 1 table, 5460 obs and 16 variables.

```{r}
#Exporting the dataframes for each table to 
# write.csv(table_1, file.path(path, 'Table 1 - Mental Health Disorders'), row.names=FALSE)
# write.csv(table_2, file.path(path, 'Table 2 - Mental Health Disorder Per Sex'), row.names=FALSE)
# write.csv(table_3, file.path(path, 'Table 3 - Suicide and Depression Per 100k'), row.names=FALSE)
# write.csv(table_4, file.path(path, 'Table 4 - Total Prevalence of Depression'), row.names=FALSE)
```

